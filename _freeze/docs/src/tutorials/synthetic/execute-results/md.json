{
  "hash": "87a430414d7edb9878cb2539943aabc0",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Synthetic Data\n---\n\n\n\n\n\n\n## Binary Classification\n\n::: {.cell execution_count=2}\n``` {.julia .cell-code}\nnobs=2000\nX, y = make_circles(nobs, noise=0.1, factor=0.5)\nX = Float32.(permutedims(matrix(X)))\ny_labels = Int.(y.refs)\ny = Flux.onehotbatch(y.refs, sort(unique(y_labels)))\ndisplay(scatter(X[1,:], X[2,:], color=vec(y_labels), label=\"\"))\nbatch_size = Int(round(nobs/10))\ntrain_set = DataLoader((X, y), batchsize=batch_size, shuffle=true)\n```\n:::\n\n\n::: {.cell execution_count=3}\n``` {.julia .cell-code}\nn_hidden = 32\nactivation = relu\nmodels = Dict(\n    \"Logistic Regression\" => Chain(Dense(2, size(y,1))),\n    \"MLP\" => Chain(\n        Dense(2, n_hidden, activation), \n        Dense(n_hidden, n_hidden, activation), \n        Dense(n_hidden, n_hidden, activation), \n        Dense(n_hidden, size(y,1))\n    ),\n)\n```\n:::\n\n\n::: {.cell execution_count=4}\n``` {.julia .cell-code}\n_loss(y_hat, y) = Flux.Losses.logitcrossentropy(y_hat, y)\nrule = Adam()\n```\n:::\n\n\n::: {.cell execution_count=5}\n``` {.julia .cell-code}\n_lims = extrema(X, dims=2)\nx1, x2 = map(ex -> range(1.1f0.*ex..., length=100), _lims)\nn_epochs = 100\nplts = []\nfor (name, model) in models\n    opt_state = Flux.setup(rule, model)\n    for epoch in 1:n_epochs\n        Flux.train!(model, train_set, opt_state) do m, x, y\n            _loss(model(x), y)\n        end\n    end\n    plt = contour(x1, x2, (x, y) -> softmax(model([x, y]))[1], fill=true, alpha=0.5, title=name, cbar=false)\n    scatter!(X[1,:], X[2,:], color=vec(y_labels), label=\"\")\n    push!(plts, plt)\nend\nplot(plts..., layout=(1, 2), size=(800, 400))\n```\n:::\n\n\n## Joint Energy Model\n\n::: {.cell execution_count=6}\n``` {.julia .cell-code}\n# We initialize the full model:\n𝒟x = Normal()\n𝒟y = Categorical(ones(2) ./ 2)\nsampler = ConditionalSampler(𝒟x, 𝒟y, input_size=size(X)[1:end-1], batch_size=batch_size)\njem = JointEnergyModel(\n    models[\"MLP\"], \n    sampler;\n    sampling_rule=ImproperSGLD(),\n    sampling_steps=10\n)\n# Initialise training:\nopt = Adam(1e-3)\nopt_state = Flux.setup(opt, jem)\nnum_epochs = 100\n```\n:::\n\n\n::: {.cell execution_count=7}\n``` {.julia .cell-code}\nlogs = JointEnergyModels.train_model(\n    jem, train_set, opt_state; \n    num_epochs=num_epochs,\n    α=[1.0,1.0,1e-1],\n    verbosity=minimum([num_epochs, 50]),\n    # use_class_loss=false,\n    # use_gen_loss=false,\n    # use_reg_loss=false,\n)\n```\n:::\n\n\n::: {.cell execution_count=8}\n``` {.julia .cell-code}\nplts = []\nfor target in 1:size(y,1)\n    plt = contour(x1, x2, (x, y) -> softmax(jem([x, y]))[target], fill=true, alpha=0.5, title=\"Target: $target\", cbar=false)\n    scatter!(X[1,:], X[2,:], color=vec(y_labels), group=vec(y_labels))\n    push!(plts, plt)\nend\nplot(plts..., layout=(1, size(y,1)), size=(size(y,1)*400, 400))\n```\n:::\n\n\n::: {.cell execution_count=9}\n``` {.julia .cell-code}\nX̂ = generate_samples(jem, 1000; niter=1000)\nŷ = onecold(softmax(jem(X̂)))\nscatter(X[1,:], X[2,:], color=vec(y_labels), group=vec(y_labels), alpha=0.5)\nscatter!(X̂[1,:], X̂[2,:], color=vec(ŷ), group=vec(ŷ), title=\"Generated Samples\", shape=:star5)\n```\n:::\n\n\n::: {.cell execution_count=10}\n``` {.julia .cell-code}\nif typeof(jem.sampler) <: ConditionalSampler\n    \n    plts = []\n    for target in 1:size(y,1)\n        X̂ = generate_conditional_samples(jem, batch_size, target; niter=1000) \n        ex = extrema(hcat(X,X̂), dims=2)\n        xlims = ex[1]\n        ylims = ex[2]\n        x1 = range(1.0f0.*xlims...,length=100)\n        x2 = range(1.0f0.*ylims...,length=100)\n        plt = contour(\n            x1, x2, (x, y) -> softmax(jem([x, y]))[target], \n            fill=true, alpha=0.5, title=\"Target: $target\", cbar=false,\n            xlims=xlims,\n            ylims=ylims,\n        )\n        scatter!(X[1,:], X[2,:], color=vec(y_labels), group=vec(y_labels), alpha=0.5)\n        scatter!(\n            X̂[1,:], X̂[2,:], \n            color=repeat([target], size(X̂,2)), \n            group=repeat([target], size(X̂,2)), \n            shape=:star5, ms=10\n        )\n        push!(plts, plt)\n    end\n    plot(plts..., layout=(1, size(y,1)), size=(size(y,1)*400, 400))\nend\n```\n:::\n\n\n",
    "supporting": [
      "synthetic_files"
    ],
    "filters": []
  }
}