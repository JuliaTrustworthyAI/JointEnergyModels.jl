
# Joint Energy Models

```{julia}
#| echo: false
include("docs/setup_docs.jl")
eval(setup_docs)
```

## Data

```{julia}
nobs = 1000
n_digits = 28

function _resize(x, size=(n_digits, n_digits))
    if n_digits != 28
        img_source = MLDatasets.convert2image(MNIST, x)
        img_rs = imresize(img_source, size)
        x = permutedims(convert(Array{Float32}, Gray.(img_rs)))
    end
    return x
end

function pre_process(x; noise::Float32=0.03f0)
    œµ = Float32.(randn(size(x)) * noise)
    x = @.(2 * x - 1) .+ œµ
    return x
end

# Train Set:
Xtrain, ytrain = MNIST(split=:train)[:]
Xtrain = Xtrain[:,:,1:nobs]
Xtrain = mapslices(x -> _resize(x), Xtrain, dims=(1,2)) 
ytrain = ytrain[1:nobs] 

# Test Set:
Xtest, ytest = MNIST(split=:test)[:]
Xtest = Xtest[:,:,1:nobs]
Xtest = mapslices(x -> _resize(x), Xtest, dims=(1,2)) 
ytest = ytest[1:nobs] 

## One-hot-encode the labels
ytrain, ytest = onehotbatch(ytrain, 0:9), onehotbatch(ytest, 0:9)

## Validation Set:
num_val = Int(round(nobs / 10))
Xtrain, Xval = (Xtrain[:,:,1:(end-num_val)], Xtrain[:,:,(end-num_val+1):end])
Xtrain = mapslices(x -> pre_process(x), Xtrain, dims=(1,2)) 
Xval = mapslices(x -> pre_process(x, noise=0.0f0), Xval, dims=(1,2)) 
ytrain, yval = (ytrain[:, 1:(end-num_val)], ytrain[:, (end-num_val+1):end])
```

## `JointEnergyModel`

## Evaluation and Training

```{julia}
function accuracy(model::JointEnergyModel, x, y; agg=mean)
    yÃÇ = jem(x)
    mean(onecold(yÃÇ) .== onecold(y))
end

function evaluation(model::JointEnergyModel, val_set::DataLoader)
    ‚Ñì = 0.0
    ‚Ñì_clf = 0.0
    ‚Ñì_gen = 0.0
    acc = 0.0
    num = 0
    for (x, y) in val_set
        ‚Ñì_clf += sum(JointEnergyModels.class_loss(model, x, y))
        ‚Ñì_gen += sum(JointEnergyModels.gen_loss(model, x))
        ‚Ñì += JointEnergyModels.loss(model, x, y)
        acc += accuracy(model, x, y)
        num += size(x)[end]
    end
    return ‚Ñì / num, ‚Ñì_clf / num, ‚Ñì_gen / num, acc / length(val_set)
end

function samples_real(model::JointEnergyModel, dl::DataLoader, n::Int=16; img_size=n_digits * 5)
    x = reduce((x, y) -> cat(x,y[1],dims=ndims(x)), dl, init = [])
    num_x = Int(round(ceil(sqrt(n))))
    num_y = Int(round(floor(sqrt(n))))
    plot_data = [heatmap(rotl90(x[:,:,rand(1:size(x)[end])]), axis=nothing, cb=false) for i in 1:n]
    plot(plot_data..., layout=(num_x, num_y), size=(num_x*img_size, num_y*img_size), margin=(round(0.05*img_size), :px))
end

function samples_generated(model::JointEnergyModel, dl::DataLoader, n::Int=16; img_size=n_digits * 5)
    x = reduce((x, y) -> cat(x,y[1],dims=ndims(x)), dl, init = [])
    x = jem.sampler(jem.chain, jem.sampling_rule, size(x))
    num_x = Int(round(ceil(sqrt(n))))
    num_y = Int(round(floor(sqrt(n))))
    plot_data = [heatmap(rotl90(x[:,:,i]), axis=nothing, cb=false) for i in 1:n]
    plot(plot_data..., layout=(num_x, num_y), size=(num_x*img_size, num_y*img_size), margin=(round(0.05*img_size), :px))
end
```

## Experiments

### Hyperparameters

```{julia}
D = n_digits               
K = 10                      
M = 32
lr = 1e-3                
num_epochs = 100
max_patience = 5            
batchsize = Int(round(nobs/10))
```

### Initializing the model

```{julia}
mlp = Chain(
    MLUtils.flatten,
    Dense(prod((D,D)), M, swish),
    # Dense(M, M, elu),
    # Dense(M, M, elu),
    Dense(M, K)
)

# We initialize the full model
ùíüx = Uniform(-1,1)
ùíüy = Categorical(ones(K) ./ K)
sampler = UnconditionalSampler(ùíüx, input_size=(D,D), batch_size=batch_size)
jem = JointEnergyModel(mlp, sampler)
```

```{julia}
n_iter = 1000
_w = 1500
plts = []
neach = 10
for i in 1:10
    x = jem.sampler(jem.chain, jem.sampling_rule; niter=n_iter, n_samples=neach)
    plts_i = []
    for j in 1:size(x, 3)
        xj = x[:,:,j]
        plts_i = [plts_i..., heatmap(rotl90(xj), axis=nothing, cb=false)]
    end
    plt = plot(plts_i..., size=(_w,0.10*_w), layout=(1,10))
    plts = [plts..., plt]
end
plot(plts..., size=(_w,_w), layout=(10,1))
```

### Training loop

```{julia}
# Initialise 
opt = Adam(lr)
opt_state = Flux.setup(opt, jem)
train_set = DataLoader((Xtrain, ytrain); batchsize=batchsize, shuffle=true)
val_set = DataLoader((Xval, yval); batchsize=batchsize, shuffle=false)
test_set = DataLoader((Xtest, ytest); batchsize=batchsize, shuffle=false)
```

```{julia}
logs = train_model(
    jem, train_set, opt_state; num_epochs=num_epochs, val_set=val_set,
    verbosity = minimum([num_epochs, 50]),
    Œ± = 1e-2,
    # use_class_loss=false,
    # use_gen_loss=false,
    # use_reg_loss=false,
)
```

### The final evaluation

```{julia}
n_iter = 1000
_w = 1500
plts = []
neach = 10
for i in 1:10
    x = jem.sampler(jem.chain, jem.sampling_rule; niter=n_iter, n_samples=neach, y=i)
    plts_i = []
    for j in 1:size(x, 3)
        xj = x[:,:,j]
        plts_i = [plts_i..., heatmap(rotl90(xj), axis=nothing, cb=false)]
    end
    plt = plot(plts_i..., size=(_w,0.10*_w), layout=(1,10))
    plts = [plts..., plt]
end
plot(plts..., size=(_w,_w), layout=(10,1))
```

```{julia}
# ‚Ñì_test, ‚Ñì_clf_test, ‚Ñì_gen_test, acc_test = evaluation(jem, test_set)
```