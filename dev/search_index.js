var documenterSearchIndex = {"docs":
[{"location":"assets/resources/#Further-Resources","page":"Further Resources","title":"Further Resources","text":"","category":"section"},{"location":"assets/resources/#JuliaCon-2022","page":"Further Resources","title":"JuliaCon 2022","text":"","category":"section"},{"location":"assets/resources/","page":"Further Resources","title":"Further Resources","text":"Slides: link","category":"page"},{"location":"assets/resources/#JuliaCon-Proceedings-Paper","page":"Further Resources","title":"JuliaCon Proceedings Paper","text":"","category":"section"},{"location":"assets/resources/","page":"Further Resources","title":"Further Resources","text":"TBD","category":"page"},{"location":"","page":"🏠 Home","title":"🏠 Home","text":"CurrentModule = JointEnergyModels","category":"page"},{"location":"#JointEnergyModels.jl","page":"🏠 Home","title":"JointEnergyModels.jl","text":"","category":"section"},{"location":"","page":"🏠 Home","title":"🏠 Home","text":"Documentation for JointEnergyModels.jl.","category":"page"},{"location":"","page":"🏠 Home","title":"🏠 Home","text":"Joint Energy Models in Julia.","category":"page"},{"location":"","page":"🏠 Home","title":"🏠 Home","text":"(Image: Stable) (Image: Dev) (Image: Build Status) (Image: Coverage) (Image: Code Style: Blue) (Image: License) (Image: Package Downloads)","category":"page"},{"location":"","page":"🏠 Home","title":"🏠 Home","text":"JointEnergyModels.jl is a package for training Joint Energy Models in Julia. Joint Energy Models (JEM) are hybrid models that learn to discriminate between classes y and generate input data x. They were introduced in Grathwohl et al. (2020), which provides the foundation for the methodologies implemented in this package.","category":"page"},{"location":"#Status","page":"🏠 Home","title":"🔁 Status","text":"","category":"section"},{"location":"","page":"🏠 Home","title":"🏠 Home","text":"This package is still in its infancy and the API is subject to change. Currently, the package can be used to train JEMs for classification. It is also possible to train pure Energy-Based Models (EBMs) for the generative task only. The package is compatible with Flux.jl. Work on compatibility with MLJ.jl (through MLJFlux.jl) is currently under way.","category":"page"},{"location":"","page":"🏠 Home","title":"🏠 Home","text":"We welcome contributions and feedback at this early stage. To install the development version of the package you can run the following command:","category":"page"},{"location":"","page":"🏠 Home","title":"🏠 Home","text":"using Pkg\nPkg.add(url=\"https://github.com/juliatrustworthyai/JointEnergyModels.jl\")","category":"page"},{"location":"#Usage-Example","page":"🏠 Home","title":"🔍 Usage Example","text":"","category":"section"},{"location":"","page":"🏠 Home","title":"🏠 Home","text":"Below we first generate some synthetic data:","category":"page"},{"location":"","page":"🏠 Home","title":"🏠 Home","text":"nobs=2000\nX, y = make_circles(nobs, noise=0.1, factor=0.5)\nXplot = Float32.(permutedims(matrix(X)))\nX = table(permutedims(Xplot))\nplt = scatter(Xplot[1,:], Xplot[2,:], group=y, label=\"\")\nbatch_size = Int(round(nobs/10))\ndisplay(plt)","category":"page"},{"location":"","page":"🏠 Home","title":"🏠 Home","text":"(Image: )","category":"page"},{"location":"","page":"🏠 Home","title":"🏠 Home","text":"The MLJ compatible classifier can be instantiated as follows:","category":"page"},{"location":"","page":"🏠 Home","title":"🏠 Home","text":"𝒟x = Normal()\n𝒟y = Categorical(ones(2) ./ 2)\nsampler = ConditionalSampler(𝒟x, 𝒟y, input_size=size(Xplot)[1:end-1], batch_size=batch_size)\nclf = JointEnergyClassifier(\n    sampler;\n    builder=MLJFlux.MLP(hidden=(32, 32, 32,), σ=Flux.relu),\n    batch_size=batch_size,\n    finaliser=x -> x,\n    loss=Flux.Losses.logitcrossentropy,\n)","category":"page"},{"location":"","page":"🏠 Home","title":"🏠 Home","text":"It uses the MLJFlux package to build the model:","category":"page"},{"location":"","page":"🏠 Home","title":"🏠 Home","text":"println(typeof(clf) <: MLJFlux.MLJFluxModel)","category":"page"},{"location":"","page":"🏠 Home","title":"🏠 Home","text":"true","category":"page"},{"location":"","page":"🏠 Home","title":"🏠 Home","text":"The model can be wrapped in data and trained using the fit! function:","category":"page"},{"location":"","page":"🏠 Home","title":"🏠 Home","text":"mach = machine(clf, X, y)\nfit!(mach)","category":"page"},{"location":"","page":"🏠 Home","title":"🏠 Home","text":"The results are visualised below. The model has learned to discriminate between the two classes (as indicated by the contours) and to generate samples from each class (as indicated by the stars).","category":"page"},{"location":"","page":"🏠 Home","title":"🏠 Home","text":"(Image: )","category":"page"},{"location":"#References","page":"🏠 Home","title":"🎓 References","text":"","category":"section"},{"location":"","page":"🏠 Home","title":"🏠 Home","text":"Grathwohl, Will, Kuan-Chieh Wang, Joern-Henrik Jacobsen, David Duvenaud, Mohammad Norouzi, and Kevin Swersky. 2020. “Your Classifier Is Secretly an Energy Based Model and You Should Treat It Like One.” In. https://openreview.net/forum?id=Hkxzx0NtDB.","category":"page"}]
}
