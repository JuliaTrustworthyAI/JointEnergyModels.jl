# Compatibility with `MLJFlux`

```{julia}
#| echo: false
include("docs/setup_docs.jl")
eval(setup_docs)
```

## Synthetic Data

```{julia}
nobs=2000
X, y = make_circles(nobs, noise=0.1, factor=0.5)
Xplot = Float32.(permutedims(matrix(X)))
X = table(permutedims(Xplot))
display(scatter(Xplot[1,:], Xplot[2,:], group=y, label=""))
batch_size = Int(round(nobs/10))
```

```{julia}
𝒟x = Normal()
𝒟y = Categorical(ones(2) ./ 2)
sampler = ConditionalSampler(𝒟x, 𝒟y, input_size=size(Xplot)[1:end-1], batch_size=batch_size)
clf = JointEnergyClassifier(
    sampler;
    builder=MLJFlux.MLP(hidden=(32, 32, 32,), σ=Flux.relu),
    batch_size=batch_size,
    finaliser=x -> x,
    loss=Flux.Losses.logitcrossentropy,
    jem_training_params=(α=0.1,verbosity=5,),
)
```

```{julia}
println(typeof(clf) <: MLJFlux.MLJFluxModel)
```

```{julia}
mach = machine(clf, X, y)
fit!(mach)
```

```{julia}
jem = mach.model.jem
batch_size = mach.model.batch_size
X = Float32.(permutedims(matrix(X)))
y_labels = Int.(y.refs)
y = Flux.onehotbatch(y.refs, sort(unique(y_labels)))
```

```{julia}
if typeof(jem.sampler) <: ConditionalSampler
    
    plts = []
    for target in 1:size(y,1)
        X̂ = generate_conditional_samples(jem, batch_size, target; niter=1000) 
        ex = extrema(hcat(X,X̂), dims=2)
        xlims = ex[1]
        ylims = ex[2]
        x1 = range(1.0f0.*xlims...,length=100)
        x2 = range(1.0f0.*ylims...,length=100)
        plt = contour(
            x1, x2, (x, y) -> softmax(jem([x, y]))[target], 
            fill=true, alpha=0.5, title="Target: $target", cbar=false,
            xlims=xlims,
            ylims=ylims,
        )
        scatter!(X[1,:], X[2,:], color=vec(y_labels), group=vec(y_labels), alpha=0.5)
        scatter!(
            X̂[1,:], X̂[2,:], 
            color=repeat([target], size(X̂,2)), 
            group=repeat([target], size(X̂,2)), 
            shape=:star5, ms=10
        )
        push!(plts, plt)
    end
    plot(plts..., layout=(1, size(y,1)), size=(size(y,1)*400, 400))
end
```

## MNIST Data

